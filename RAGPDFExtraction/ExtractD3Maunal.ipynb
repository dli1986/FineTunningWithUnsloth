{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9900676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Raw segments sample (2100:2130):\n",
      "  [2100] Type: example, Parent: _CP_release_all, Content: /*The following example releases all previously se...\n",
      "  [2101] Type: content, Parent: _CP_replace, Content: equivalent to the FlashBASIC statement: result = r...\n",
      "  [2102] Type: syntax, Parent: _CP_replace, Content: int _CP_replace(CPSTR** result, CPSTR* string1, in...\n",
      "  [2103] Type: example, Parent: _CP_replace, Content: /* The following example prints \"c^b\". */ CPSTR * ...\n",
      "  [2104] Type: content, Parent: _CP_replace_bridge, Content: equivalent to the following FlashBASIC statement: ...\n",
      "  [2105] Type: syntax, Parent: _CP_replace_bridge, Content: int _CP_replace_bridge(int expression, CPSTR* stri...\n",
      "  [2106] Type: content, Parent: _CP_rewind, Content: equivalent to the FlashBASIC statement: rewind typ...\n",
      "  [2107] Type: syntax, Parent: _CP_rewind, Content: int _CP_rewind(int type)...\n",
      "  [2108] Type: example, Parent: _CP_rewind, Content: /* The following example rewinds the tape. */ _CP_...\n",
      "  [2109] Type: content, Parent: _CP_root, Content: equivalent to the FlashBASIC statement: root strin...\n",
      "  [2110] Type: syntax, Parent: _CP_root, Content: int _CP_root(CPSTR* string1, CPSTR* string2, int* ...\n",
      "  [2111] Type: example, Parent: _CP_root, Content: /* The following gets the first item-id which cont...\n",
      "  [2112] Type: content, Parent: _CP_rs_, Content: converts a double floating point number into a CPS...\n",
      "  [2113] Type: syntax, Parent: _CP_rs_, Content: CPSTR * _CP_rs_(double number)...\n",
      "  [2114] Type: example, Parent: _CP_rs_, Content: CPSTR * s = _CP_rs_(1.123); _CP_print(s); This exa...\n",
      "  [2115] Type: content, Parent: _CP_SADDR, Content: returns a standard char* pointing to the first cha...\n",
      "  [2116] Type: syntax, Parent: _CP_SADDR, Content: char* _CP_SADDR(CPSTR* string)...\n",
      "  [2117] Type: example, Parent: _CP_SADDR, Content: CPSTR * s = _CP_mkstr(\"hi\"); _CP_SADDR(s)[1] = 'o'...\n",
      "  [2118] Type: content, Parent: _CP_select, Content: equivalent to the following FlashBASIC statement: ...\n",
      "  [2119] Type: syntax, Parent: _CP_select, Content: int _CP_select(int expression1, int* list, int exp...\n",
      "  [2120] Type: example, Parent: _CP_select, Content: The following example prints the item names in \"my...\n",
      "  [2121] Type: content, Parent: _CP_send, Content: equivalent to the FlashBASIC statement: send{x} st...\n",
      "  [2122] Type: syntax, Parent: _CP_send, Content: int _CP_send(int type, CPSTR* string, int port.num...\n",
      "  [2123] Type: example, Parent: _CP_send, Content: /* The following example sends \"hi\" to port 1. */ ...\n",
      "  [2124] Type: content, Parent: _CP_si_, Content: converts a CPSTR into an integer....\n",
      "  [2125] Type: syntax, Parent: _CP_si_, Content: int _CP_si_(CPSTR * string)...\n",
      "  [2126] Type: example, Parent: _CP_si_, Content: CPSTR * s = _CP_mkstr(\"3.12345\"); int i; i = _CP_s...\n",
      "  [2127] Type: content, Parent: _CP_sleep, Content: equivalent to the FlashBASIC statement: sleep(stri...\n",
      "  [2128] Type: syntax, Parent: _CP_sleep, Content: int _CP_sleep(CPSTR* string)...\n",
      "  [2129] Type: example, Parent: _CP_sleep, Content: /* sleep 5 seconds */ CPSTR * s = _CP_mkstr(\"5\"); ...\n",
      "\n",
      "DEBUG: After merging - sample segments:\n",
      "  [100] Title:  - hot backup\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [101] Title:  - hung port\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [102] Title:  - i\n",
      "      Has Content: True\n",
      "      Has Syntax: True\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [103] Title:  - incremental restore\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [104] Title:  - incremental save\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [105] Title:  - installation\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [106] Title:  - internal format\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [107] Title:  - item\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [108] Title:  - item-id\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "  [109] Title:  - levels\n",
      "      Has Content: True\n",
      "      Has Syntax: False\n",
      "      Has Examples: 0\n",
      "      Has Options: False\n",
      "Extracted 2445 knowledge segments from PDF\n",
      "DEBUG: Starting export_for_rag with 2138 segments\n",
      "DEBUG: Finished export_for_rag, created 2138 documents\n",
      "Extracted 2138 merged knowledge segments:\n",
      "\n",
      "=== Section Component Summary ===\n",
      "General: 16 segments (0 with syntax, 0 total examples, 0 with options)\n",
      "Attribute-defining Items: 125 segments (1 with syntax, 28 total examples, 1 with options)\n",
      "Definitions: 131 segments (8 with syntax, 17 total examples, 0 with options)\n",
      "AQL: 114 segments (57 with syntax, 73 total examples, 28 with options)\n",
      "Tape: 36 segments (27 with syntax, 13 total examples, 19 with options)\n",
      "Background Process: 7 segments (5 with syntax, 1 total examples, 1 with options)\n",
      "FlashBASIC: 405 segments (337 with syntax, 273 total examples, 3 with options)\n",
      "Unix: 28 segments (15 with syntax, 13 total examples, 4 with options)\n",
      "Index: 11 segments (9 with syntax, 7 total examples, 0 with options)\n",
      "Spooler: 30 segments (23 with syntax, 20 total examples, 14 with options)\n",
      "TCL: 538 segments (357 with syntax, 270 total examples, 195 with options)\n",
      "FlashBASIC Debugger: 35 segments (18 with syntax, 17 total examples, 0 with options)\n",
      "C Functions: 119 segments (112 with syntax, 106 total examples, 0 with options)\n",
      "Editor: 37 segments (18 with syntax, 33 total examples, 0 with options)\n",
      "System Files: 59 segments (1 with syntax, 7 total examples, 0 with options)\n",
      "Output Processor: 91 segments (84 with syntax, 40 total examples, 4 with options)\n",
      "Proc: 83 segments (37 with syntax, 31 total examples, 0 with options)\n",
      "Processing Codes: 59 segments (28 with syntax, 30 total examples, 2 with options)\n",
      "Runoff: 64 segments (51 with syntax, 21 total examples, 5 with options)\n",
      "System Debugger: 40 segments (27 with syntax, 25 total examples, 0 with options)\n",
      "Update Processor: 104 segments (85 with syntax, 13 total examples, 1 with options)\n",
      "Customer Service: 6 segments (0 with syntax, 1 total examples, 0 with options)\n",
      "\n",
      "=== Sample Merged Segments ===\n",
      "\n",
      "--- General Component ---\n",
      "\n",
      "Title:  - Overview\n",
      "Component: General\n",
      "Page: 4\n",
      "Has Syntax: False\n",
      "Has Options: False\n",
      "Examples: 0\n",
      "Content Preview: The Pick Systems Reference Manual contains entries specific to the features of D\n",
      "3\n",
      ".\n",
      "The manual is d...\n",
      "\n",
      "Title:  - Ordering\n",
      "Component: General\n",
      "Page: 4\n",
      "Has Syntax: False\n",
      "Has Options: False\n",
      "Examples: 0\n",
      "Content Preview: Direct orders for additional manuals to:\n",
      "Pick Systems 1691 Browning Irvine, CA 92606 Attention: Orde...\n",
      "\n",
      "--- Attribute-defining Items Component ---\n",
      "\n",
      "Title:  - Dictionaries as Operators\n",
      "Component: Attribute-defining Items\n",
      "Page: 9\n",
      "Has Syntax: False\n",
      "Has Options: False\n",
      "Examples: 0\n",
      "Content Preview: The D\n",
      "3\n",
      "dictionary is a file consisting of items that contain 18 attributes. Each dictionary item\n",
      "ca...\n",
      "\n",
      "Title:  - D3 Dictionary Structure\n",
      "Component: Attribute-defining Items\n",
      "Page: 10\n",
      "Has Syntax: False\n",
      "Has Options: False\n",
      "Examples: 0\n",
      "Content Preview: System Dictionary\n",
      "(mds, one per system)\n",
      "Master Dictionary\n",
      "Master Dictionary\n",
      "(one per account)\n",
      "File\n",
      "D...\n",
      "\n",
      "Exported 2138 merged documents to merged_knowledge_segments.jsonl\n",
      "Detailed report saved to extraction_report.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class KnowledgeSegment:\n",
    "    \"\"\"Represents a semantic knowledge segment\"\"\"\n",
    "    title: str\n",
    "    content: str\n",
    "    syntax: str  # Syntax information if available\n",
    "    examples: List[str]  # List of examples \n",
    "    options: str  # Options information if available\n",
    "    level: int  # Hierarchy level (0=main section, 1=subsection, etc.)\n",
    "    page_number: int\n",
    "    segment_type: str  # 'section', 'definition', 'example', 'syntax', 'options'\n",
    "    section_component: str  # The main component this segment belongs to\n",
    "\n",
    "class PDFKnowledgeExtractor:\n",
    "    def __init__(self):\n",
    "        # Font size thresholds for different hierarchy levels\n",
    "        self.main_heading_size = 14  # Main sections like \"Definitions\", \"AQL (Access)\"\n",
    "        self.sub_heading_size = 10   # Sub-items like \"assembly language\", \"total\"\n",
    "        self.body_text_size = 9      # Regular content\n",
    "        \n",
    "        # Patterns for different content types\n",
    "        self.definition_pattern = r'^[a-zA-Z][a-zA-Z0-9\\s_-]+$'\n",
    "        self.example_pattern = r'^\\s*Example\\s*$'\n",
    "        self.syntax_pattern = r'^\\s*Syntax\\s*$'\n",
    "        self.options_pattern = r'^\\s*Options\\s*$'\n",
    "        \n",
    "        # Header/footer patterns that indicate section components\n",
    "        self.header_footer_patterns = [\n",
    "            r'^Pick Systems Reference Manual$',\n",
    "            r'^Definitions$',\n",
    "            r'^AQL \\(Access\\)$',\n",
    "            r'^Page \\d+$',\n",
    "            r'^Attribute\\-defining Items$',\n",
    "            r'^Background\\/Phantom Process$',\n",
    "            r'^Pick\\/BASIC\\—FlashBASIC$',\n",
    "            r'^FlashBASIC Debugger$',\n",
    "            r'^C Functions$',\n",
    "            r'^Editor$',\n",
    "            r'^System Files$',\n",
    "            r'^Output Processor$',\n",
    "            r'^Proc$',\n",
    "            r'^Processing Codes$',\n",
    "            r'^Runoff$',\n",
    "            r'^Spooler$',\n",
    "            r'^System Debugger$',\n",
    "            r'^Tape$',\n",
    "            r'^TCL$',\n",
    "            r'^Update processor \\(UP\\)$',\n",
    "            r'^Unix$',\n",
    "            r'^Index$',\n",
    "            r'^Customer Service$',\n",
    "            r'^Reader\\'s Comments$',\n",
    "        ]\n",
    "        \n",
    "        # Map section headers to component names\n",
    "        self.section_component_map = {\n",
    "            'Pick Systems Reference Manual': 'General',\n",
    "            'Definitions': 'Definitions',\n",
    "            'AQL (Access)': 'AQL',\n",
    "            'Attribute-defining Items': 'Attribute-defining Items',\n",
    "            'Background/Phantom Process': 'Background Process',\n",
    "            'Pick/BASIC—FlashBASIC': 'FlashBASIC',\n",
    "            'FlashBASIC Debugger': 'FlashBASIC Debugger',\n",
    "            'C Functions': 'C Functions',\n",
    "            'Editor': 'Editor',\n",
    "            'System Files': 'System Files',\n",
    "            'Output Processor': 'Output Processor',\n",
    "            'Proc': 'Proc',\n",
    "            'Processing Codes': 'Processing Codes',\n",
    "            'Runoff': 'Runoff',\n",
    "            'Spooler': 'Spooler',\n",
    "            'System Debugger': 'System Debugger',\n",
    "            'Tape': 'Tape',\n",
    "            'TCL': 'TCL',\n",
    "            'Update processor (UP)': 'Update Processor',\n",
    "            'Unix': 'Unix',\n",
    "            'Index': 'Index',\n",
    "            'Customer Service': 'Customer Service',\n",
    "            'Reader\\'s Comments': 'Reader Comments',\n",
    "        }\n",
    "        \n",
    "    def extract_text_with_formatting(self, pdf_path: str) -> List[Dict]:\n",
    "        \"\"\"Extract text with formatting information from PDF\"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        formatted_blocks = []\n",
    "        \n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "            \n",
    "            for block in blocks:\n",
    "                if \"lines\" in block:  # Text block\n",
    "                    for line in block[\"lines\"]:\n",
    "                        for span in line[\"spans\"]:\n",
    "                            text = span[\"text\"].strip()\n",
    "                            if text:  # Skip empty text\n",
    "                                formatted_blocks.append({\n",
    "                                    'text': text,\n",
    "                                    'font_size': span[\"size\"],\n",
    "                                    'font_flags': span[\"flags\"],  # Bold, italic flags\n",
    "                                    'bbox': span[\"bbox\"],  # Bounding box for position\n",
    "                                    'page': page_num + 1\n",
    "                                })\n",
    "        \n",
    "        doc.close()\n",
    "        return formatted_blocks\n",
    "    \n",
    "    def is_bold(self, font_flags: int) -> bool:\n",
    "        \"\"\"Check if text is bold based on font flags\"\"\"\n",
    "        return bool(font_flags & 2**4)  # Bold flag\n",
    "    \n",
    "    def get_indentation_level(self, bbox: Tuple[float, float, float, float]) -> int:\n",
    "        \"\"\"Determine indentation level based on x-coordinate\"\"\"\n",
    "        x0 = bbox[0]\n",
    "        if x0 < 80:\n",
    "            return 0  # Main heading\n",
    "        elif x0 < 140:\n",
    "            return 1  # First level indent\n",
    "        elif x0 < 180:\n",
    "            return 2  # Second level indent\n",
    "        else:\n",
    "            return 3  # Deep indent\n",
    "    \n",
    "    def is_page_header_footer(self, text: str) -> bool:\n",
    "        \"\"\"Identify page headers, footers, and page numbers\"\"\"\n",
    "        text_clean = text.strip()\n",
    "        \n",
    "        for pattern in self.header_footer_patterns:\n",
    "            if re.match(pattern, text_clean, re.IGNORECASE):\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_section_component_from_header(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract section component name from header text, excluding generic headers\"\"\"\n",
    "        text_clean = text.strip()\n",
    "        \n",
    "        # Skip generic headers that don't indicate section changes\n",
    "        generic_headers = [\n",
    "            r'^Pick Systems Reference Manual$',\n",
    "            r'^Page \\d+$',\n",
    "        ]\n",
    "        \n",
    "        for generic_pattern in generic_headers:\n",
    "            if re.match(generic_pattern, text_clean, re.IGNORECASE):\n",
    "                return None\n",
    "        \n",
    "        # Check against known section headers\n",
    "        for pattern in self.header_footer_patterns:\n",
    "            if re.match(pattern, text_clean, re.IGNORECASE):\n",
    "                # Find the corresponding component name\n",
    "                for section_name, component_name in self.section_component_map.items():\n",
    "                    if re.match(pattern, section_name, re.IGNORECASE):\n",
    "                        return component_name\n",
    "                \n",
    "                # If no mapping found, clean the text and use as component\n",
    "                clean_text = re.sub(r'[^\\w\\s]', '', text_clean).strip()\n",
    "                return clean_text if clean_text else None\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def track_page_sections_smart(self, blocks: List[Dict]) -> Dict[int, str]:\n",
    "        \"\"\"Smart tracking of section components, handling alternating headers\"\"\"\n",
    "        page_sections = {}\n",
    "        current_section = \"General\"  # Default section\n",
    "        section_changes = {}  # Track where sections change\n",
    "        \n",
    "        # First pass: identify actual section changes\n",
    "        for block in blocks:\n",
    "            page_num = block['page']\n",
    "            text = block['text']\n",
    "            \n",
    "            # Check if this is a meaningful section header (not generic)\n",
    "            section_component = self.get_section_component_from_header(text)\n",
    "            if section_component:\n",
    "                section_changes[page_num] = section_component\n",
    "        \n",
    "        # Second pass: assign sections to all pages\n",
    "        current_section = \"General\"\n",
    "        for page_num in range(1, max(block['page'] for block in blocks) + 1):\n",
    "            # Check if this page has a section change\n",
    "            if page_num in section_changes:\n",
    "                current_section = section_changes[page_num]\n",
    "            \n",
    "            page_sections[page_num] = current_section\n",
    "        \n",
    "        return page_sections\n",
    "    \n",
    "    def is_content_continuation(self, current_block: Dict, next_block: Dict) -> bool:\n",
    "        \"\"\"Determine if next block is a continuation of current content across pages\"\"\"\n",
    "        # Different pages but similar formatting\n",
    "        if current_block['page'] != next_block['page']:\n",
    "            # Check if formatting is similar (same font size and flags)\n",
    "            font_match = abs(current_block['font_size'] - next_block['font_size']) < 1\n",
    "            flag_match = current_block['font_flags'] == next_block['font_flags']\n",
    "            \n",
    "            # Check if the content logically continues (starts with lowercase or continuation words)\n",
    "            next_text = next_block['text'].strip()\n",
    "            continuation_indicators = [\n",
    "                next_text[0].islower() if next_text else False,  # Starts with lowercase\n",
    "                next_text.startswith(('and', 'or', 'but', 'the', 'to', 'of', 'in', 'on', 'at', 'for')),\n",
    "                not next_text[0].isupper() if next_text else False,  # Not starting with capital\n",
    "            ]\n",
    "            \n",
    "            return font_match and flag_match and any(continuation_indicators)\n",
    "        \n",
    "        # Same page - use original logic\n",
    "        return (abs(current_block['font_size'] - next_block['font_size']) < 1 and\n",
    "                current_block['font_flags'] == next_block['font_flags'] and\n",
    "                abs(current_block['bbox'][0] - next_block['bbox'][0]) < 10)\n",
    "    \n",
    "    def classify_content_type(self, text: str, font_size: float, is_bold: bool, indent_level: int) -> str:\n",
    "        \"\"\"Classify the type of content based on formatting and text\"\"\"\n",
    "        text_lower = text.lower().strip()\n",
    "        text_clean = text.strip()\n",
    "        \n",
    "        # Skip page headers and footers\n",
    "        if self.is_page_header_footer(text):\n",
    "            return 'page_header_footer'\n",
    "        \n",
    "        # Main section headers\n",
    "        if font_size >= self.main_heading_size and is_bold and indent_level == 0:\n",
    "            return 'main_section'\n",
    "        \n",
    "        # Special keywords - improved detection\n",
    "        # Exact matches for section headers\n",
    "        if text_clean.lower() in ['example', 'syntax', 'options']:\n",
    "            return text_clean.lower()\n",
    "        \n",
    "        # Pattern matches for section headers with colons or other punctuation\n",
    "        if re.match(r'^(example|syntax|options)\\s*[:.-]?\\s*$', text_lower):\n",
    "            if 'example' in text_lower:\n",
    "                return 'example'\n",
    "            elif 'syntax' in text_lower:\n",
    "                return 'syntax'\n",
    "            elif 'options' in text_lower:\n",
    "                return 'options'\n",
    "        \n",
    "        # Definition headers (bold, medium size, indented)\n",
    "        if is_bold and font_size >= self.sub_heading_size and indent_level == 1:\n",
    "            return 'definition_header'\n",
    "        \n",
    "        # Regular content\n",
    "        return 'content'\n",
    "    \n",
    "    def merge_continuation_lines(self, blocks: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Merge text blocks that are part of the same paragraph\"\"\"\n",
    "        merged_blocks = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(blocks):\n",
    "            current_block = blocks[i].copy()\n",
    "            \n",
    "            # Skip if this is a page header/footer\n",
    "            if self.is_page_header_footer(current_block['text']):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Look ahead for continuation lines\n",
    "            j = i + 1\n",
    "            while j < len(blocks):\n",
    "                next_block = blocks[j]\n",
    "                \n",
    "                # Skip page headers/footers in continuation checking\n",
    "                if self.is_page_header_footer(next_block['text']):\n",
    "                    j += 1\n",
    "                    continue\n",
    "                \n",
    "                # Check if next block is a continuation\n",
    "                if self.is_content_continuation(current_block, next_block):\n",
    "                    # Merge the text\n",
    "                    current_block['text'] += ' ' + next_block['text']\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            merged_blocks.append(current_block)\n",
    "            i = j\n",
    "        \n",
    "        return merged_blocks\n",
    "    \n",
    "    def extract_knowledge_segments_with_merging(self, pdf_path: str) -> List[KnowledgeSegment]:\n",
    "        \"\"\"Extract and merge related knowledge segments (content, syntax, examples, options)\"\"\"\n",
    "        formatted_blocks = self.extract_text_with_formatting(pdf_path)\n",
    "        \n",
    "        # Smart tracking of section components\n",
    "        page_sections = self.track_page_sections_smart(formatted_blocks)\n",
    "        \n",
    "        merged_blocks = self.merge_continuation_lines(formatted_blocks)\n",
    "        \n",
    "        # Intermediate segments before merging\n",
    "        raw_segments = []\n",
    "        current_main_section = \"\"\n",
    "        current_subsection = \"\"\n",
    "        current_content = []\n",
    "        current_level = 0\n",
    "        current_page = 1\n",
    "        current_section_component = \"General\"\n",
    "        current_content_type = \"content\"  # Track current content type\n",
    "        \n",
    "        for block in merged_blocks:\n",
    "            text = block['text']\n",
    "            font_size = block['font_size']\n",
    "            is_bold = self.is_bold(block['font_flags'])\n",
    "            indent_level = self.get_indentation_level(block['bbox'])\n",
    "            content_type = self.classify_content_type(text, font_size, is_bold, indent_level)\n",
    "            page_num = block['page']\n",
    "            \n",
    "            # Update current section component based on page\n",
    "            if page_num in page_sections:\n",
    "                current_section_component = page_sections[page_num]\n",
    "            \n",
    "            # Skip page headers/footers\n",
    "            if content_type == 'page_header_footer':\n",
    "                continue\n",
    "            \n",
    "            if content_type == 'main_section':\n",
    "                # Only treat as new main section if different\n",
    "                if text != current_main_section:\n",
    "                    # Save previous section if exists\n",
    "                    if current_main_section and current_content:\n",
    "                        raw_segments.append({\n",
    "                            'title': current_main_section,\n",
    "                            'content': '\\n'.join(current_content),\n",
    "                            'level': 0,\n",
    "                            'page_number': current_page,\n",
    "                            'segment_type': current_content_type,  # Use current_content_type\n",
    "                            'section_component': current_section_component,\n",
    "                            'parent_key': current_main_section\n",
    "                        })\n",
    "                    \n",
    "                    current_main_section = text\n",
    "                    current_subsection = \"\"\n",
    "                    current_content = []\n",
    "                    current_level = 0\n",
    "                    current_page = page_num\n",
    "                    current_content_type = \"content\"  # Reset to content for main sections\n",
    "                \n",
    "            elif content_type == 'definition_header':\n",
    "                # Save previous subsection if exists\n",
    "                if current_subsection and current_content:\n",
    "                    raw_segments.append({\n",
    "                        'title': f\"{current_main_section} - {current_subsection}\",\n",
    "                        'content': '\\n'.join(current_content),\n",
    "                        'level': 1,\n",
    "                        'page_number': current_page,\n",
    "                        'segment_type': current_content_type,  # Use current_content_type\n",
    "                        'section_component': current_section_component,\n",
    "                        'parent_key': current_subsection\n",
    "                    })\n",
    "                \n",
    "                current_subsection = text\n",
    "                current_content = []\n",
    "                current_level = 1\n",
    "                current_page = page_num\n",
    "                current_content_type = \"content\"  # Reset to content for new definition\n",
    "                \n",
    "            elif content_type in ['example', 'syntax', 'options']:\n",
    "                # Save current content first if exists\n",
    "                if current_content:\n",
    "                    title = current_subsection if current_subsection else current_main_section\n",
    "                    parent_key = current_subsection if current_subsection else current_main_section\n",
    "                    raw_segments.append({\n",
    "                        'title': f\"{current_main_section} - {title}\",\n",
    "                        'content': '\\n'.join(current_content),\n",
    "                        'level': current_level,\n",
    "                        'page_number': current_page,\n",
    "                        'segment_type': current_content_type,  # Use current_content_type\n",
    "                        'section_component': current_section_component,\n",
    "                        'parent_key': parent_key\n",
    "                    })\n",
    "                \n",
    "                # Start collecting example/syntax/options content\n",
    "                current_content = []\n",
    "                current_content_type = content_type  # Update content type to match what we're collecting\n",
    "                \n",
    "            else:  # Regular content\n",
    "                current_content.append(text)\n",
    "        \n",
    "        # Don't forget the last segment\n",
    "        if current_content:\n",
    "            title = current_subsection if current_subsection else current_main_section\n",
    "            parent_key = current_subsection if current_subsection else current_main_section\n",
    "            raw_segments.append({\n",
    "                'title': f\"{current_main_section} - {title}\" if current_subsection else current_main_section,\n",
    "                'content': '\\n'.join(current_content),\n",
    "                'level': current_level,\n",
    "                'page_number': current_page,\n",
    "                'segment_type': current_content_type,  # Use current_content_type\n",
    "                'section_component': current_section_component,\n",
    "                'parent_key': parent_key\n",
    "            })\n",
    "        \n",
    "        print(\"DEBUG: Raw segments sample (2100:2130):\")\n",
    "        for i, seg in enumerate(raw_segments[2100:2130], 2100):\n",
    "            print(f\"  [{i}] Type: {seg['segment_type']}, Parent: {seg['parent_key']}, Content: {seg['content'][:50]}...\")\n",
    "        \n",
    "        # Now merge related segments by parent_key\n",
    "        merged_result = self.merge_related_segments(raw_segments)\n",
    "        \n",
    "        print(f\"\\nDEBUG: After merging - sample segments:\")\n",
    "        for i, seg in enumerate(merged_result[100:110], 100):\n",
    "            print(f\"  [{i}] Title: {seg.title}\")\n",
    "            print(f\"      Has Content: {bool(seg.content.strip())}\")\n",
    "            print(f\"      Has Syntax: {bool(seg.syntax.strip())}\")\n",
    "            print(f\"      Has Examples: {len(seg.examples)}\")\n",
    "            print(f\"      Has Options: {bool(seg.options.strip())}\")\n",
    "        \n",
    "        return merged_result\n",
    "    \n",
    "    def merge_related_segments(self, raw_segments: List[Dict]) -> List[KnowledgeSegment]:\n",
    "        \"\"\"Merge content, syntax, examples, and options for the same knowledge item\"\"\"\n",
    "        merged_segments = []\n",
    "        segment_groups = {}\n",
    "        \n",
    "        # Group segments by parent_key and section_component\n",
    "        for segment in raw_segments:\n",
    "            key = f\"{segment['section_component']}::{segment['parent_key']}\"\n",
    "            \n",
    "            if key not in segment_groups:\n",
    "                segment_groups[key] = {\n",
    "                    'content': [],\n",
    "                    'syntax': [],\n",
    "                    'examples': [],\n",
    "                    'options': [],\n",
    "                    'title': segment['title'],\n",
    "                    'level': segment['level'],\n",
    "                    'page_number': segment['page_number'],\n",
    "                    'segment_type': segment['segment_type'],\n",
    "                    'section_component': segment['section_component']\n",
    "                }\n",
    "            \n",
    "            content = segment['content']\n",
    "            segment_type = segment['segment_type']  # Use the actual segment_type from raw data\n",
    "            \n",
    "            # Distribute content based on segment_type\n",
    "            if segment_type == 'syntax':\n",
    "                # Preserve \"Syntax\" label if not already present\n",
    "                if not content.strip().startswith('Syntax'):\n",
    "                    syntax_content = f\"Syntax\\n{content}\"\n",
    "                else:\n",
    "                    syntax_content = content\n",
    "                segment_groups[key]['syntax'].append(syntax_content)\n",
    "                \n",
    "            elif segment_type == 'example':\n",
    "                # Preserve \"Example\" label if not already present\n",
    "                if not content.strip().startswith('Example'):\n",
    "                    example_content = f\"Example\\n{content}\"\n",
    "                else:\n",
    "                    example_content = content\n",
    "                segment_groups[key]['examples'].append(example_content)\n",
    "                \n",
    "            elif segment_type == 'options':\n",
    "                # Preserve \"Options\" label if not already present\n",
    "                if not content.strip().startswith('Options'):\n",
    "                    options_content = f\"Options\\n{content}\"\n",
    "                else:\n",
    "                    options_content = content\n",
    "                segment_groups[key]['options'].append(options_content)\n",
    "                \n",
    "            else:  # content or other types\n",
    "                # Regular content\n",
    "                segment_groups[key]['content'].append(content)\n",
    "        \n",
    "        # Convert grouped segments to KnowledgeSegment objects\n",
    "        for key, group in segment_groups.items():\n",
    "            merged_segments.append(KnowledgeSegment(\n",
    "                title=group['title'],\n",
    "                content='\\n\\n'.join(group['content']) if group['content'] else '',\n",
    "                syntax='\\n\\n'.join(group['syntax']) if group['syntax'] else '',\n",
    "                examples=group['examples'],  # Keep as list since examples are handled separately\n",
    "                options='\\n\\n'.join(group['options']) if group['options'] else '',\n",
    "                level=group['level'],\n",
    "                page_number=group['page_number'],\n",
    "                segment_type=group['segment_type'],\n",
    "                section_component=group['section_component']\n",
    "            ))\n",
    "        \n",
    "        return merged_segments\n",
    "    \n",
    "    def filter_segments(self, segments: List[KnowledgeSegment], \n",
    "                       min_content_length: int = 30) -> List[KnowledgeSegment]:\n",
    "        \"\"\"Filter out segments that are too short or not meaningful\"\"\"\n",
    "        filtered = []\n",
    "        for segment in segments:\n",
    "            # Skip table of contents and index-like content\n",
    "            if any(keyword in segment.title.lower() for keyword in \n",
    "                   ['table of contents', 'index', 'customer service', \"reader's comments\"]):\n",
    "                continue\n",
    "            \n",
    "            # Calculate total content length - now including options\n",
    "            total_content = segment.content + segment.syntax + segment.options + ' '.join(segment.examples)\n",
    "            \n",
    "            # Skip very short content\n",
    "            if len(total_content.strip()) < min_content_length:\n",
    "                continue\n",
    "            \n",
    "            filtered.append(segment)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def export_for_rag(self, segments: List[KnowledgeSegment], \n",
    "                  output_format: str = 'jsonl') -> List[Dict]:\n",
    "        \"\"\"Export segments in a format suitable for RAG pipeline with separate fields\"\"\"\n",
    "        print(f\"DEBUG: Starting export_for_rag with {len(segments)} segments\")\n",
    "        rag_documents = []\n",
    "        \n",
    "        for i, segment in enumerate(segments):\n",
    "            \n",
    "            # Create separate fields for each content type\n",
    "            doc = {\n",
    "                'id': f\"doc_{i:04d}\",\n",
    "                'title': segment.title,\n",
    "                'content': segment.content.strip() if segment.content else '',\n",
    "                'syntax': segment.syntax.strip() if segment.syntax else '',\n",
    "                'examples': segment.examples if segment.examples else [],\n",
    "                'options': segment.options.strip() if segment.options else '',\n",
    "                'metadata': {\n",
    "                    'level': segment.level,\n",
    "                    'page_number': segment.page_number,\n",
    "                    'segment_type': segment.segment_type,\n",
    "                    'section_component': segment.section_component,\n",
    "                    'has_syntax': bool(segment.syntax),\n",
    "                    'has_examples': bool(segment.examples),\n",
    "                    'has_options': bool(segment.options),\n",
    "                    'example_count': len(segment.examples),\n",
    "                    'content_length': len(segment.content) if segment.content else 0,\n",
    "                    'syntax_length': len(segment.syntax) if segment.syntax else 0,\n",
    "                    'options_length': len(segment.options) if segment.options else 0\n",
    "                }\n",
    "            }\n",
    "            rag_documents.append(doc)\n",
    "        \n",
    "        print(f\"DEBUG: Finished export_for_rag, created {len(rag_documents)} documents\")\n",
    "        return rag_documents\n",
    "\n",
    "# Usage example\n",
    "def main():\n",
    "    extractor = PDFKnowledgeExtractor()\n",
    "    \n",
    "    # Extract knowledge segments with smart merging\n",
    "    pdf_path = r\"C:\\RocketBuild\\Manual_D3.pdf\"  # Replace with your PDF path\n",
    "    segments = extractor.extract_knowledge_segments_with_merging(pdf_path)\n",
    "    print(f\"Extracted {len(segments)} knowledge segments from PDF\")\n",
    "\n",
    "    # Filter segments\n",
    "    filtered_segments = extractor.filter_segments(segments)\n",
    "    \n",
    "    # Export for RAG pipeline\n",
    "    rag_documents = extractor.export_for_rag(filtered_segments)\n",
    "    \n",
    "    # Display results with section component information\n",
    "    print(f\"Extracted {len(filtered_segments)} merged knowledge segments:\")\n",
    "    \n",
    "    # Group by section component for better overview\n",
    "    by_component = {}\n",
    "    for segment in filtered_segments:\n",
    "        component = segment.section_component\n",
    "        if component not in by_component:\n",
    "            by_component[component] = []\n",
    "        by_component[component].append(segment)\n",
    "    \n",
    "    # Show summary by component\n",
    "    print(\"\\n=== Section Component Summary ===\")\n",
    "    for component, segs in by_component.items():\n",
    "        syntax_count = sum(1 for seg in segs if seg.syntax)\n",
    "        example_count = sum(len(seg.examples) for seg in segs)\n",
    "        options_count = sum(1 for seg in segs if seg.options)\n",
    "        print(f\"{component}: {len(segs)} segments ({syntax_count} with syntax, {example_count} total examples, {options_count} with options)\")\n",
    "    \n",
    "    # Show sample merged segments\n",
    "    print(\"\\n=== Sample Merged Segments ===\")\n",
    "    for component, segs in list(by_component.items())[:2]:  # Show first 2 components\n",
    "        print(f\"\\n--- {component} Component ---\")\n",
    "        for segment in segs[:2]:  # Show first 2 segments per component\n",
    "            print(f\"\\nTitle: {segment.title}\")\n",
    "            print(f\"Component: {segment.section_component}\")\n",
    "            print(f\"Page: {segment.page_number}\")\n",
    "            print(f\"Has Syntax: {bool(segment.syntax)}\")\n",
    "            print(f\"Has Options: {bool(segment.options)}\")\n",
    "            print(f\"Examples: {len(segment.examples)}\")\n",
    "            if segment.content:\n",
    "                print(f\"Content Preview: {segment.content[:100]}...\")\n",
    "            if segment.syntax:\n",
    "                print(f\"Syntax Preview: {segment.syntax[:100]}...\")\n",
    "            if segment.options:\n",
    "                print(f\"Options Preview: {segment.options[:100]}...\")\n",
    "            if segment.examples:\n",
    "                print(f\"Example Preview: {segment.examples[0][:100]}...\")\n",
    "    \n",
    "    # Save to file for RAG pipeline\n",
    "    import json\n",
    "    with open('merged_knowledge_segments.jsonl', 'w', encoding='utf-8') as f:\n",
    "        for doc in rag_documents:\n",
    "            f.write(json.dumps(doc, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"\\nExported {len(rag_documents)} merged documents to merged_knowledge_segments.jsonl\")\n",
    "    \n",
    "    # Save detailed report\n",
    "    with open('extraction_report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"PDF Knowledge Extraction Report (Fixed Merging)\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Section Component Summary:\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\n\")\n",
    "        for component, segs in by_component.items():\n",
    "            syntax_count = sum(1 for seg in segs if seg.syntax)\n",
    "            example_count = sum(len(seg.examples) for seg in segs)\n",
    "            options_count = sum(1 for seg in segs if seg.options)\n",
    "            f.write(f\"{component}: {len(segs)} segments ({syntax_count} with syntax, {example_count} examples, {options_count} with options)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nTotal merged segments: {len(filtered_segments)}\\n\")\n",
    "        f.write(f\"Total pages processed: {max(seg.page_number for seg in filtered_segments)}\\n\")\n",
    "        \n",
    "        # Statistics\n",
    "        total_with_syntax = sum(1 for seg in filtered_segments if seg.syntax)\n",
    "        total_with_examples = sum(1 for seg in filtered_segments if seg.examples)\n",
    "        total_with_options = sum(1 for seg in filtered_segments if seg.options)\n",
    "        total_examples = sum(len(seg.examples) for seg in filtered_segments)\n",
    "        \n",
    "        f.write(f\"\\nStatistics:\\n\")\n",
    "        f.write(f\"- Segments with syntax: {total_with_syntax}\\n\")\n",
    "        f.write(f\"- Segments with examples: {total_with_examples}\\n\")\n",
    "        f.write(f\"- Segments with options: {total_with_options}\\n\")\n",
    "        f.write(f\"- Total examples: {total_examples}\\n\")\n",
    "    \n",
    "    print(\"Detailed report saved to extraction_report.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
